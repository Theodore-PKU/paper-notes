# Learning Continuous Image Representation with Local Implicit Image Function

[TOC]

### 信息

Authors: Yinbo Chen, Sifei Liu, and Xiaolong Wang

UC San Diego and NVIDIA

引用：0

[Paper](/Users/xieyutong/Documents/Research/PaperReading/Papers/learning-continuous-image-representation-with-local-implicit-image-function.pdf)



### Code

https://yinboc.github.io/liif/



### 概括

这篇文章提出了 Local Implicit Image Function (LIIF)，这个函数的输入是图像特征和坐标，输出是像素值。由于坐标是连续的，因此 LIIF 是一个连续函数。作者使用这个函数来表示图像，并且可以针对任意的分辨率。作者还考虑到每个坐标在不同的分辨率下对应的像素面积大小是不同的，所以还增加了一个新的特征表示像素面积的大小。作者通过一个自监督的超分辨任务实现对 encoder (应该和图像特征提取有关) 和 LIIF 的训练。作者表示这种方法可以拓展到其他需要对 ground truth 的 size 进行修改的任务中，会比仅仅 resize 的表现更好。总的来说，这篇文章提出的方法建立了图像 2D 离散和连续之间的一种联系。

详细一些的说明：LIIF 实际是一个全连接网络 + 双线性插值，这里的输入实际上仅仅针对某一个具体位置，这个位置不是特征图的格点坐标，而是和要生成的图像有关的更细的位置坐标，特征选择的是和这个位置最接近的位置。图像特征通过和超分辨相关的神经网络提供（去掉了其中的上采样层）。自监督训练的意思是，原始图像当作是 HR 图像，通过下采样得到 LR 图像，因此是自监督学习。size-varied image ground-truth 的应用值得是在最终输出的地方，加上一个 LIIF 层，那么就可以得到不同分辨率的输出已满足。ground-truth size 不同的情况。实际考虑的还是一个超分辨的任务。

思考：由于全连接网络本质和 1x1 卷积是一样的，所以也可以理解成是某种特征图的插值 + 连续的 1x1 卷积。所以这篇文章值得思考的是如何加入坐标的信息。1x1 卷积和坐标信息似乎很配。



### 思路

视觉世界是连续的，但是一般的图像表示却是离散的二维矩阵。作者的想法受到 3d shape reconstruction 的一些工作启发，使用了 implicit function 的形式。

implicit function 是将坐标映射到相应信号的函数。neural implicit function 则是一个用深度神经网络来表示的函数。

为了避免 implicit function 只针对某一个目标，一种做法是利用一个 encoder 进行特征提取，将这个提取的特征作为函数的输入之一。这样就可以用于所有的目标。

此前也有一些工作考虑了图像的 implicit function 表示，但是图像是数字，作者认为这是因为很难将所有的细节信息都表达在一个简单的隐变量中。

> 这是否意味着和隐变量表示之间存在关系。

作者的特征提取（latent code）是分布在空间维度的（似乎就是每个位置有单独的隐变量表示），作者提出的 LIIF 的输入是坐标以及坐标附近的 loca latent code，输出是 RGB 像素值。由于坐标是连续的，所以输出也是连续的。LIIF 的具体形式使得给定一个坐标，就可以得到一个输出。我个人理解的坐标实际上是在原来的坐标基础上的一个插值。不过这里的坐标的具体取法需要看代码才清楚，论文似乎没有说明坐标的表示形式，这也涉及到特征图的格点的坐标形式。

为了生成分辨率更高的图像，作者的特征提取网络 encoder 通过自监督超分辨任务实现。此前的超分辨的工作一般都是固定的 scale，而 LIIF 利用坐标的连续性，可以取到更细的位置的像素值，这样就可以实现几乎任意的分辨率放大。实验中是 30x，甚至超过训练使用的 scale。



### 贡献

一个新的局部 implicit image function

可以实现 30x 的超分辨，而训练的时候不需要考虑这么大的超分辨。

提出的方法可以用于 ground-truth 是不同 size 的任务。



### LIIF 模型

#### 基本形式

基本形式是一个 MLP 神经网络。$s = f(z, x)$，其中 $z$ 是特征向量，$x$ 是 2d 坐标，$s$ 是输出的像素值。

假设有一个特征图 $M^{(i)}$，那么连续图像 $I^{(i)}$ 的某个位置 $x_q$ 的像素值的计算是：
$$
\begin{equation}
I^{(i)}\left(x_{q}\right)=f\left(z^{*}, x_{q}-v^{*}\right)
\end{equation}
$$
$z^*$ 是离 $x_q$ 最近的特征图格点的特征向量，$v^*$ 是该格点的坐标，所以第二个参数实际是一个相对坐标。

#### Feature unfolding

这是作者提出的一个改进，其实就是特征图的特征向量从当前格点变成包含当前格点的 3x3 区域 9 个格点的所有特征向量的 concatetation，构成一个混合的特征图，也可以理解成一个局部特征图。对于边界区域，使用 0 向量。

#### Local ensemble

在基本形式中，如果 $x_1$ 和 $x_2$ 的位置恰好分属相邻的格点，但是它们挨得无穷接近，此时参与计算的特征向量是不同的，但是两个位置实际是连续的，这可能会带来不连续的断点。为了避免这一点，作者考虑使用类似于双线性插值的做法进行加权平均。
$$
\begin{equation}
I^{(i)}\left(x_{q}\right)=\sum_{t \in\{00,01,10,11\}} \frac{S_{t}}{S} \cdot f\left(z_{t}^{*}, x_{q}-v_{t}^{*}\right)
\end{equation}
$$
在这个式子中，$z^*$ 不再是最近邻的像素值，而是周围四个像素值。计算方式仍然是 (1) 的形式，加权的 $S_t$ 则是和对角那个格点位置构成的矩形的大小，$S$ 是面积的和。因此加权就是比重的加权。如果 $x$ 离左上角的格点近，那么矩形就是右下角的矩形。这个实际就是一种插值平滑。至于边界，这里考虑了镜像的计算方式。

#### Cell decoding

这个其实就是在坐标信息的基础上增加了一个面积信息。面积信息指的是给定放大倍数的情况下，每个像素位置所表示的面积大小，和长宽边长有关。因此原来的 LIIF 的形式变成了：
$$
\begin{equation}
s=f_{c e l l}(z,[x, c])
\end{equation}
$$
$c = [c_h, c_w]$

作者的想法就是不同的分辨率，即使是相同的位置，也是不一样的，这个像素的大小是有关的。



### 实验

#### 实验框架

作者的实验是超分辨任务。采用自监督的形式，所以会对 ground-truth 做下采样得到 input 图像。作者考虑不同的下采样率，得到不同 size 的 input，为了方便训练，实际的输入是固定 size 的 patch 图像。这个输入图像经过一个 encoder 得到和输入相同大小的特征图。然后接 LIIF 模块，这个时候输出图像的大小取决于 LIIF 输入的坐标值。如果输入的坐标值对应更大的分辨率，那么输出的图像就更细致。当然这里并不要求输出的 size 一定放大了。因为只要控制输入的坐标，实际上也可以得到比较小的图像，而这个比较小的图像就是正常放大之后的一部分了。比如放大倍数为 4，原始的输入的格点坐标是 1～8，那么放大之后的格点坐标应该是 0.25, 0.5, 0.75, 1, ..., 8, ... 只要选取 2 ～ 3 范围的坐标，输出的图像就还是 8x8.

计算损失函数的时候，只要 label 取对应的 patch 就可以了。

![屏幕快照 2020-12-23 下午9.19.03](/Users/xieyutong/Pictures/screenshot/屏幕快照 2020-12-23 下午9.19.03.png)

作者使用了 L1 的损失函数。而为了训练方便，输出的图像大小也是一致的。



#### 实验细节

数据集是 DIV2K，包含 1000 张 2K 分辨率的图像。

训练的时候，考虑的放大倍数是 1～4. 注意，这里的放大倍数是连续的。因为任意一个放大倍数，总是可以计算坐标值和像素面积，因此是可行的。

测试的时候，还会测试 6～30 的放大情况。我的理解是比较对象都是原始的 2K 图像，所以即使是放大 30x，只是 input 变得更小了。

作者采用 48x48 的patch 大小。而输出也是 48x48 大小（毕竟放大倍数有的可能很小）

encoder 采用的 EDSR-baseline 或 RDN，都是其他的超分辨任务。我感觉特征提取的网络本身可能不是这篇文章的重点。

LIIF 的 MLP 是五层的网络，隐层节点数量是 256.

下采样用的是 Pytorch 的 bicubic resizing



#### 实验结果

![屏幕快照 2020-12-23 下午9.27.18](/Users/xieyutong/Pictures/screenshot/屏幕快照 2020-12-23 下午9.27.18.png)

实验结果还是不错的。这个图是 30x 放大，可以看到放大效果还是很好。MetaSR 都出现棋盘状伪影了。这里比较的 1-SIREN 是另一个 implicit function，但是没有用 encoder 的提取特征，是针对每个图像单独训练一个 MLP 的方法。

从 PSNR 的指标上看，对于训练范围内的放大倍数，LIIF 的结果不一定是最好的，但是在更大的放大倍数情况下，效果都会好不少。



#### 消融实验

这篇文章的消融实验主要是考虑 cell decoding，feature unfolding, local ensemble 和 MLP 的网络深度的影响。

其中核心结果是：

![屏幕快照 2020-12-23 下午9.31.54](/Users/xieyutong/Pictures/screenshot/屏幕快照 2020-12-23 下午9.31.54.png)

这些影响其上都不是特别大，虽然普遍都会差一点。这其实也暴露出这篇文章的问题。真正和超分辨有关的是 encoder 的特征提取。LIIF 仅仅是一个 1x1 卷积。只不过这篇文章用这个形式实现了完全的位置控制。

关于不使用 cell decoding，效果反而在更大的分辨率下效果变好，作者的解释是 PSNR 倾向于平均的结果，而 LIIF 产生的图像有一些 uncertainty. 作者认为图像质量从视觉上来说是更好的。



#### 应用于 size-varied ground-truth

作者考虑的还是一个超分辨任务，只是不再是自然图像，因此不适合使用 patch 的训练方法。作者这里用的是人脸数据集，作者表示在这种特定分布的任务下，一般要完整地生成一张图像。所以如果 ground-truth 大小不一致，常规做法是先对 label 进行 resize 处理。

而使用 LIIF 的模型，可以在特征提取（这部分可以用原来的模型）之后，用 LIIF 得到不同的 size 的输出。不过输入都是一样的 size（换句话说放大的倍数是不同的）


### 反思

用坐标和 implicit function 这种形式确实可以达到对于像素位置的很好的控制，不过实际上相当于一个 1x1 卷积，而卷积的对象不仅仅是原来的格点，而是格点之间的位置，有一点像对特征图的插值（就像张默师姐的多尺度卷积计算一样）。不过这个 implicit function 的思路能不能用到图像生成上？实际上图像生成和超分辨有着千丝万缕的联系。

不过我感觉现在的模型，隐变量和 hierarchical 的结构需要更细的思考。这些隐变量包含了什么信息？











