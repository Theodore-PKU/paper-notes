### Paper:

Exploiting correlations among channels in distributed compressive sensing with convolutional deep stacking networks

### Author:

Hamid Palangi, Rabab Ward, Li Deng

### Year:

2016

### Notes:

这篇文章处理的压缩感知问题和一般的压缩感知有一些区别，普通的压缩感知只考虑一个向量，称为Single Measurement Vector (SMV)，这篇文章则是多个向量，称为Multiple Measurement Vectors (MMV)。因此需要同时重建多个向量。

> 如果信号没有一定的相似性，MMV和SMV没有什么区别。

作者提出的方法分为两个阶段。1. 找到最大支撑对应的idx，也就是哪个稀疏分量影响最大（相对残差而言）；2. 用最小二乘求解出系数。依次重复，直到残差很小为止。作者的设定里，要恢复的向量本身就是稀疏的。

找到最大支撑的方法类似于LSTM。在已知所有向量的测量残差（残差的计算方式是 $y_i - A_{\Omega_i}s(\Omega_i)$, $\Omega$ 表示已知的稀疏分量的idx集合）的基础上，生成对剩下的还未确定的idx的值，找到其中最大的，定为下一个要恢复的idx。为了实现这一点，需要特别处理才有训练数据。作者的做法是先剔除最大支撑，计算剩余分量对应的残差 $\mathbf{r}_{i}=\mathbf{y}_{i}-\mathbf{A}_{\Omega_{i}} s\left(k_{0}\right)$，然后把剩余分量（最大支撑idx设为0）作为target，残差作为输入。因为要考虑整体的结构，所以网络的输入是多个向量。按照这种做法可以对一个已有的数据创建多个pair。实际重建的时候就是逐次找到剩余最大支撑的idx。

整体的想法是这样的，但是很多细节文章的说明不够清楚。因此不细看了。不过，这种做法非常少见，不知道有什么可以发挥的地方。

<img src="https://raw.githubusercontent.com/Theodore-PKU/pictures/master/%E6%88%AA%E5%B1%8F2019-12-15%E4%B8%8B%E5%8D%8810.15.37.png" style="zoom:67%;" />

### Bibtex:

```latex
@inproceedings{palangi2016exploiting,
  title={Exploiting correlations among channels in distributed compressive sensing with convolutional deep stacking networks},
  author={Palangi, Hamid and Ward, Rabab and Deng, Li},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2692--2696},
  year={2016},
  organization={IEEE}
}
```