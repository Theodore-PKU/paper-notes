



# 思路和证明

[TOC]

## 思路概述

### 问题描述

在研究神经网络的表达能力的文献中，有一个方向是计算空间划分的数量。对于激活函数是 ReLU 的神经网络来说，该网络表示的函数是分片线性函数，分片的产生是因为 ReLU 导致某些神经元未被激活，因此相当于输入空间被划分成不同的区域，每个区域对应一个激活 pattern。我们的目标是对给定的网络，计算出它所能表示的分片线性函数的分片数量的上界。



### 思路

Serra 2018 （bounding and counting ...）的那篇文章给出了一个形式上很不错的上界。目前我们可以给出一个更紧的上界，但是计算比较复杂。Hinz 2019（a framework ...）这篇文章虽然没有给出新的上界，但是给出了一个比较简洁的计算框架（矩阵运算），Serra 2018 的上界计算和我们给出的上界计算都可以用这个框架表示。因此最基本的工作是利用 Hinz 2019 这篇文章提出的概念和计算框架来描述我们给出的上界。因为这个上界的计算只考虑了最简单的全连接 ReLU 网络，所以我们在此基础上把更复杂的网络结构，包括 pooling、skip connection 等也考虑进来，也用矩阵的形式计算包含这些复杂结构的网络的分片数量的上界。



## A Framework for the construction of upper bounds on the number of aﬃne linear regions of ReLU feed-forward neural networks 中的相关概念和记号

我们沿用这些记号和概念

### 记号

$h$：$\mathbb{R}^{n} \rightarrow \mathbb{R}^{n^{\prime}}, x \mapsto\left(\sigma\left(\left\langle x, w_{i}^{(h)}\right\rangle+b_{i}^{(h)}\right)\right)_{i \in\left\{1, \ldots, n^{\prime}\right\}}$，线性层 + ReLU 层

$RL(n,n'):=\left\{h: \mathbb{R}^{n} \rightarrow \mathbb{R}^{n^{\prime}} | h \text { is a ReLU Layer function }\right\}$，$h$ 的集合，也就是单层网络

$H^{h}_i:=\left\{x \in \mathbb{R}^{n} |\left\langle x, w_{i}^{(h)}\right\rangle+b_{i}^{(h)}=0\right\} \subset \mathbb{R}^{n} \quad \text { for } i \in\left\{1, \ldots, n^{\prime}\right\}$，$h$ 的第 $i$ 个超平面

$\mathrm{RL}\left(n_{0}, \mathbf{n}\right):=\operatorname{RL}\left(n_{0}, n_{1}\right) \times \operatorname{RL}\left(n_{1}, n_{2}\right) \times \cdots \times \operatorname{RL}\left(n_{L-1}, n_{L}\right), \mathbf{n}=\left(n_{1}, \ldots, n_{L}\right) \in \mathbb{N}_{+}^{L}$，$L$ 层网络的各层函数集合，也可以表示为 $\mathbf{h}=\left(h_{1}, \ldots, h_{L}\right) \in \mathrm{RL}\left(n_{0}, \mathbf{n}\right)$，网络记为：
$$
f_{\mathbf{h}}:\left\{\begin{array}{ll}\mathbb{R}^{n_{0}} & \rightarrow \mathbb{R}^{n_{L}} \\x & \mapsto h_{L} \circ \cdots \circ h_{1}(x)\end{array}\right.
$$

### 定义

$S_{h}(x) \in\{0,1\}^{n^{\prime}}$ 表示输入 $x$ 在 $h$ 运算中的激活 pattern

$R_{h}(s):=\left\{x \in \mathbb{R}^{n} | S_{h}(x)=s\right\}$：单层网络某一激活 pattern 对应的输入空间的区域

$\mathcal{S}_{h}:=\left\{S_{h}(x) \in\{0,1\}^{n^{\prime}} | x \in \mathbb{R}^{n}\right\}$：$h$ 运算下所有可能的激活 pattern

$S_{\mathbf{h}}(x)=\left(S_{h_{1}}(x), S_{h_{2}}\left(h_{1}(x)\right), \ldots, S_{h_{L}}\left(h_{L-1} \circ \cdots \circ h_{1}(x)\right)\right)$：多层网络的激活 pattern

$R_{\mathbf{h}}(s):=\left\{x \in \mathbb{R}^{n_{0}} | S_{\mathbf{h}}(x)=s\right\}$：多层网络的某一激活 pattern 对应的输入空间的区域。

$\mathcal{S}_{\mathbf{h}}:=\left\{S_{\mathbf{h}}(x) \in\{0,1\}^{n_{1}} \times \cdots \times\{0,1\}^{n_{L}} | x \in \mathbb{R}^{n_{0}}\right\}$：多层网络的所有可能的激活 pattern

我们所关心的就是 $|\mathcal{S}_{\mathbf{h}}|$ 的大小。激活 pattern 数量和区域划分数量的关系是：
$$
N_{f_{\mathrm{h}}} \leq\left|\mathcal{S}_{\mathbf{h}}\right|
$$
定义激活 pattern 序列：
$$
\begin{aligned}&\mathcal{S}_{\mathbf{h}}^{(1)}:=\left\{\left(s_{1}\right) \in\{0,1\}^{n_{1}} |\left(s_{1}, \ldots, s_{L}\right):=s \in \mathcal{S}_{\mathrm{h}}\right\}\\&\mathcal{S}_{\mathbf{h}}^{(2)}:=\left\{\left(s_{1}, s_{2}\right) \in\{0,1\}^{n_{1}} \times\{0,1\}^{n_{2}} |\left(s_{1}, \ldots, s_{L}\right):=s \in \mathcal{S}_{\mathbf{h}}\right\}\\&\vdots\\&\mathcal{S}_{\mathbf{h}}^{(L)}:=\quad\left\{\left(s_{1}, \ldots, s_{L}\right) \in\{0,1\}^{n_{1}} \times \cdots \times\{0,1\}^{n_{L}} |\left(s_{1}, \ldots, s_{L}\right):=s \in \mathcal{S}_{\mathrm{h}}\right\}=\mathcal{S}_{\mathrm{h}}\end{aligned}
$$
这个激活 pattern 序列的含义就是随着网络的一层一层的前向计算，网络输入的不同区域对应的激活 pattern 的集合。



**核心定义 histgram**：$\tilde{\mathcal{H}}^{(l)}\left(\mathcal{S}_{\mathrm{h}}^{(l)}\right)$ 为集合 $ \left\{\min \left(n_{0},\left|s_{1}\right|, \ldots,\left|s_{l}\right|\right)| s \in \mathcal{S}_{\mathbf{h}}^{(l)}\right\}$ 的 histogram，表示当前所有激活 pattern 的最小值 $\min\{n_0, |s_i|\}$ 的分布。$\min \left(n_{0},\left|s_{1}\right|, \ldots,\left|s_{l}\right|\right)$ 表示了某一激活 pattern $s$ 对应的区域经过 $\mathbf{h}$ 的运算得到的值域的最大可能维度，因此 $\tilde{\mathcal{H}}^{(l)}\left(\mathcal{S}_{\mathrm{h}}^{(l)}\right)$  表示了当前所有划分出来的区域经过 $\mathbf{h}$ 的运算后的值域的最大可能维度的分布。



严格的写法是：
$$
\mathcal{H}_{n^{\prime}}:\left\{\begin{array}{ll}
\mathcal{P}\left(\{0,1\}^{n^{\prime}}\right) & \rightarrow V \\
\mathcal{S} & \mapsto\left(\sum_{s \in \mathcal{S}} \mathbb{1}_{\{j\}}(|s|)\right)_{j \in \mathbb{N}}
\end{array}\right.\\
\tilde{\mathcal{H}}^{(l)}:\left\{\begin{array}{ll}
\mathcal{P}\left(\{0,1\}^{n_{1}} \times \cdots \times\{0,1\}^{n_{l}}\right) & \rightarrow V \\
U & \mapsto\left(\sum_{\left(s_{1}, \dots, s_{l}\right) \in U} \mathbb{1}_{\{j\}}\left(\min \left(n_{0},\left|s_{1}\right|, \ldots,\left|s_{l}\right|\right)\right)\right)_{j \in \mathbb{N}_{0}}
\end{array}\right.
$$
这两个定义则分别表示单层和多层网络的一个激活 pattern 集合对应的 histgram 的计算。

histgram 本身的定义可以看成是一个无限维的向量。**对于 histgram，可以定义比较运算 $\preceq$，以及 $\max$ 运算。**

比较运算的定义：
$$
v \preceq w \quad: \Longleftrightarrow \forall J \in \mathbb{N}: \sum_{j=J}^{\infty} v_{j} \leq \sum_{j=J}^{\infty} w_{j}
$$
<img src="/Users/xieyutong/Library/Application Support/typora-user-images/image-20200427113126073.png" alt="image-20200427113126073" style="zoom:50%;" />

$\max$ 运算的定义：
$$
\max _{i \in I}\left(v^{(i)}\right)_{J}=\max _{i \in I}\left(\sum_{j=J}^{\infty} v_{j}^{(i)}\right)-\max _{i \in I}\left(\sum_{j=J+1}^{\infty} v_{j}^{(i)}\right) \quad \text { for } J \in \mathbb{N}
$$
比较运算刻画了一个性质：总是希望划分以后的空间的维度尽可能大，这样进一步划分的数量会更多。

借助比较运算，我们的目的是得到下列的表达式：
$$
\begin{aligned}
\tilde{\mathcal{H}}^{(1)}\left(\mathcal{S}_{\mathbf{h}}^{(1)}\right) & \preceq \varphi_{n_{1}}^{(\gamma)}\left(\mathbf{e}_{n_{0}}\right) \\
\tilde{\mathcal{H}}^{(l+1)}\left(\mathcal{S}_{\mathbf{h}}^{(l+1)}\right) & \preceq \varphi_{n_{l+1}}^{(\gamma)}\left(\tilde{\mathcal{H}}^{(l)}\left(\mathcal{S}_{\mathbf{h}}^{(l)}\right)\right) \quad \text { for } l \in\{1, \ldots, L-1\}
\end{aligned}
$$
通过 histgram的 变换来确定最终的空间划分数量，而 $\varphi^{\gamma}_{n_i}$ 表示 histgram 的变化关系。

问题的核心就转化成确定 $\varphi^{\gamma}_{n_i}$，这里的 $\gamma$ 表示一个参数，不同的 $\gamma$ 决定了 $\varphi^{\gamma}_{n_i}$ 的好坏，决定了最终计算出来的区域划分数量的上界。



### 关于 $\varphi^{\gamma}_{n_i}$ 的详细计算说明

下面的定义给出了 $\gamma$ 的 具体内容：

1. $\forall n^{\prime} \in \mathbb{N}_{+}, n \in\left\{0, \ldots, n^{\prime}\right\} \quad \max \left\{\mathcal{H}_{n^{\prime}}\left(\mathcal{S}_{h}\right) | h \in \operatorname{RL}\left(n, n^{\prime}\right)\right\} \preceq \gamma_{n, n^{\prime}}$
2. $\forall n^{\prime} \in \mathbb{N}_{+}, n, \tilde{n} \in\left\{0, \ldots, n^{\prime}\right\} \quad n \leq \tilde{n} \Longrightarrow \gamma_{n, n^{\prime}} \preceq \gamma_{\tilde{n}, n^{\prime}}$

$n'\in \mathbb{N}^+,0\leq n\leq n'$

$\gamma_{n,n'}$ 表示当输入空间的维度是 $n$，划分的超平面数量是 $n'$ 时，对于输入空间的划分区域的值域的激活 pattern 的激活神经元数量的分布（是一个 histgram）的上界。

第一个条件的含义是 $\gamma_{n,n'}$ 的一个定义，它应该满足大于等于任何一个 $n$ 维输入空间、$n'$ 个超平面划分结果的值域的激活 pattern 的激活神经元数量的分布 histgram，因此也大于等于其输出 image 的维数 histgram。

第二个条件的含义是当输入空间的维数变大时，相同数量的超平面划分的上界 histgram 满足大小关系。

这两个条件刻画了递推式的本质含义。

为了方便，对于 $n = 0$ 的特殊定义：
$$
n^{\prime} \in \mathbb{N}_{+}, \operatorname{RL}\left(0, n^{\prime}\right)=\left\{h:\{0\} \rightarrow \mathbb{R}^{n^{\prime}}, x \mapsto c | c \in \mathbb{R}\right\}\\h \in \mathrm{RL}\left(0, n^{\prime}\right), \mathcal{H}_{n^{\prime}}\left(\mathcal{S}_{h}\right)=\mathrm{e}_{0}
$$
满足条件的 $\gamma_{n,n'}$ 的集合记为 $\Gamma$。对于 $n > n'$ 的情形，$\gamma_{n,n'}$ 取 $n = n'$  的情形即可。

注意：在这里 histgram 有两个具体含义，一个是 $\gamma_{n,n'}$ 中的激活 pattern 的激活神经元数量的 histgram，另一个是输出 image 的维度大小的 histgram。

考虑到输出 image 的维数小于等于输入空间的维数，因此即便激活 pattern 的激活神经元数量比 $n$ 大，最终的 image 的维度仍然是小于等于 $n$。所以为了建立 $\gamma$ （激活 pattern 的激活神经元数量的 histgram）到 $\tilde{\mathcal{H}}^{(l)}\left(\mathcal{S}_{\mathbf{h}}^{(l)}\right)$ （输出 image 的维度的 histgram），定义一个功能性函数 clipping function，作用在某一个 histgram 上：
$$
\mathrm{cl}_{i^{*}}(v)_{i}=\left\{\begin{array}{ll}v_{i} & \text { for } i<i^{*} \\ \sum_{j=i^{*}}^{\infty} v_{j} & \text { for } i=i^{*} \\ 0 & \text { for } i>i^{*}\end{array}\right.
$$
<img src="/Users/xieyutong/Library/Application Support/typora-user-images/image-20200427113000777.png" alt="image-20200427113000777" style="zoom:50%;" />

则有：
$$
\left(\sum_{s \in \mathcal{S}_{h}} \mathbb{1}_{\{i\}}\left(\operatorname{rank} \text { of } h \text { on } R_{h}(s)\right)\right) \quad \preceq \mathrm{cl}_{n}\left(\gamma_{n, n^{\prime}}\right)
$$
因此可以定义：
$$
\varphi_{n^{\prime}}^{(\gamma)}:\left\{\begin{array}{ll}
V & \rightarrow V \\
v & \mapsto \sum_{n=0}^{\infty} v_{n} \mathrm{cl}_{\min \left(n, n^{\prime}\right)}\left(\gamma_{\min \left(n, n^{\prime}\right), n^{\prime}}\right)
\end{array}\right.
$$
利用 $v_1 \preceq v_2$ 可以推出 $\left\|v_{1}\right\|_{1} \leq\left\|v_{2}\right\|_{1}$，我们所关心的区域划分的上界 $\left|\mathcal{S}_{\mathbf{h}}\right|$ 可以表示为
$$
\left|\mathcal{S}_{\mathbf{h}}\right|=\left\|\tilde{\mathcal{H}}^{(L)}\left(\mathcal{S}_{\mathbf{h}}^{(L)}\right)\right\|_{1} \leq\left\|\varphi_{n_{L}}^{(\gamma)} \circ \cdots \circ \varphi_{n_{1}}^{(\gamma)}\left(\mathrm{e}_{n_{0}}\right)\right\|_{1} \quad \text { for } \gamma \in \Gamma
$$

### 最终形式

上述的计算恰好可以写成矩阵形式：
$$
\left(B_{n^{\prime}}^{(\gamma)}\right)_{i, j}=\left(\varphi_{n^{\prime}}^{(\gamma)}\left(\mathrm{e}_{j-1}\right)\right)_{i-1}=\left(\mathrm{cl}_{j-1}\left(\gamma_{j-1, n^{\prime}}\right)\right)_{i-1} \quad \text { for } i, j \in\left\{1, \ldots, n^{\prime}+1\right\}
$$
定义连接矩阵：
$$
M_{n, n^{\prime}} \in \mathbb{R}^{n^{\prime}+1 \times n+1}, \quad M_{i, j}=\delta_{i, \min \left(j, n^{\prime}+1\right)} \text { for } i \in\left\{1, \ldots, n^{\prime}+1\right\}, j \in\{1, \ldots, n+1\}
$$
例子：
$$
M_{4,2}=\left(\begin{array}{ccccc}1 & 0 & 0 & 0 & 0 \\0 & 1 & 0 & 0 & 0 \\0 & 0 & 1 & 1 & 1\end{array}\right), \quad M_{2,4}=\left(\begin{array}{ccc}1 & 0 & 0 \\0 & 1 & 0 \\0 & 0 & 1 \\0 & 0 & 0 \\0 & 0 & 0\end{array}\right)
$$
最终的计算为：
$$
\left|\mathcal{S}_{\mathbf{h}}\right| \leq\left\|B_{n_{L}}^{(\gamma)} M_{n_{L-1}, n_{L}} \ldots B_{n_{1}}^{(\gamma)} M_{n_{0}, n_{1}} e_{n_{0}+1}\right\|_{1}
$$
连接矩阵并不是必须的，只是为了写法上和 $B_{n'}^{(\gamma)}$ 相匹配。



上述内容简单说明了 Hinz 2019 这篇文章的计算框架，数学工具是 histgram 和相关的运算定义。计算形式是矩阵。核心是确定 $\gamma$ 的值。


## Bounding and Counting Linear Regions of Deep Neural Networks, Thiago Serra, Christian Tjandraatmadja, Srikumar Ramalingam, 2018, ICML 的上界在矩阵框架下的应用

任何一个上界，计算的核心是参数 $\gamma$，这里用 $\gamma_{n,n'}(i)$ 表示 $\gamma_{n,n'}$ 的第 $i$ 个分量（注意第一个分量是取值 0 的数量，为了记号上的方便，$i$ 从 0 开始） 。

在 2018 年的这篇文章中，有表达式：
$$
\left\{\begin{array}{ll}
0 & 0\leq i < n'-n\\
\left(\begin{array}{c}
n' \\
n'-i
\end{array}\right) & \max\{n'-n,0\} \leq i \leq n'
\end{array}\right.
$$
具体的例子 $\gamma_{\cdot,5}$

<img src="/Users/xieyutong/Library/Application Support/typora-user-images/image-20200502113122818.png" alt="image-20200502113122818" style="zoom: 50%;" />

经过 clipping 函数的计算，可以得到 $B^{\gamma}_{5}$

<img src="/Users/xieyutong/Library/Application Support/typora-user-images/image-20200502113149630.png" alt="image-20200502113149630" style="zoom:50%;" />



Hinz 2019 这篇文章证明了 Serra 2018 提出的上界和上述的 $\gamma$ 定义下的计算结果是一样。



## 我们提出的上界计算

这部分会给出我们提出的相关内容的详细证明。

**定义** downward-move 运算（histgram 到 histgram）：
$$
\text{dm}(v)_i = \left\{\begin{array}{ll}
0 & i = 0\\
v_{i-1} & i >0
\end{array}\right.
$$
这个运算可以看成是 histgram 的下标的移动和开头分量的补 0。

首先我们计算出 $n=1$ 时的，$\gamma_{1,n'}$ 的最小取值，换言之 $\max \left\{\mathcal{H}_{n^{\prime}}\left(\mathcal{S}_{h}\right) | h \in \operatorname{RL}\left(0, n^{\prime}\right)\right\} \preceq \gamma_{0, n^{\prime}}$ 的最紧的上界（因为存在某种划分，使得该上界可以达到），并给出严格的证明。

**命题 1** 在 1 维情形下，$\max \left\{\mathcal{H}_{n^{\prime}}\left(\mathcal{S}_{h}\right) | h \in \operatorname{RL}\left(0, n^{\prime}\right)\right\} = (0,\cdots,0, n'\mod{2},2,\cdots,2,1)^{T}$，$n'\mod{2}$ 的位置是 $n'- \lfloor (n')/2\rfloor$。最后一个 1 的位置是 $n'+1$。

**这个命题我证错了，哭了**😭

证明：首先举个例子，$n'=5$ 时，$\max \left\{\mathcal{H}_{n^{\prime}}\left(\mathcal{S}_{h}\right) | h \in \operatorname{RL}\left(0, n^{\prime}\right)\right\} = [0,0,1,2,2,1]$。这个问题也可以表述为在数轴取 $n'$ 个点 $x_1,x_2, \cdots, x_{n'}$，这些点将数轴分割成 $n'+1$ 个部分。每个点确定一个方向，决定该点右侧或左侧的区域在该点是否激活（对应神经元的激活），每个区域对应的激活值不同，激活值的个数就是 $\mathcal{H}_{n^{\prime}}\left(\mathcal{S}_{h}\right)$，$h$ 由 $x_1, \cdots, x_{n'}$ 决定。

证明思路是从分割点的两边开始，我们证明对任意的分割点的方向的分配，只要左侧一半的分割点中，第一个（从左开始数）方向朝左的分割点，将其方向改为朝右，那么得到的 histgram 和先前的 histgram 满足 $\succeq$ 关系。类似的右侧一半的分割点中，第一个（从右开始数）方向朝右的分割点，将其方向改为朝左后，得到的 histgram 和先前的 histgram 满足 $\succeq$ 关系。因此可以建立一个 histgram 的序列满足 $v_0 \preceq v_1 \preceq \cdots \preceq v_e$，对应初始的分割点方向的分配和后续的变化，最终变成左侧一半的所有分割点都朝右，右侧一半的所有分割点都朝左（对于分割点为奇数个时，中间的分割点的朝向是左或者右都是等价的）。 

因为两侧是对称的，对右侧一半的分割点的朝向变动，存在镜像的左侧一半分割点的朝向变动，因此只证明左侧，右侧忽略。设 $n$ 个分割点，分割的区域记为 $r_1, ..., r_{n+1}$，对应的激活的个数为 $\{k_1, k_2, ... k_{n+1}\}$。这里先证明一个小引理：$|k_i - k_{i+1}| = 1$. 对于相邻的区域 $r_i, r_{i+1}$，除了分割 $x_i$ 处的激活情况不同，其他分割点的激活都是一样的，所以激活个数差 1 或 -1，符号取决于 $x_i$ 的朝向。

用归纳法。从最左侧的分割点 $x_1$ 开始，若 $x_1$ 的朝向向左，设当前的 histgram 为 $v_0$，此时的不同区域的激活个数是 $\{k_1, k_2, ..., k_{n+1}\}$。将 $x_1$ 的朝向改成向右，此时的不同区域的激活个数容易计算出是 $\{k_1-1, k_2+1, k_3+1, ..., k_{n+1}+1\}$，因为 $x_1$ 原来朝左，所以，$k_1 = k_2 + 1$，因此此时的激活个数也可以表示为 $\{k_2, k_1, k_3+1, ..., k_{n+1}+1\}$，它对应的 histgram 记为 $v_1$。显然 $v_1 \succeq v_0$ 。若 $x_1$ 的朝向朝右，那么由刚才的分析可知，如果改为朝左后，$v_0 \succeq v_1$，所以对于这种情形不需要改变 $x_1$ 的朝向。假设从最左侧的分割点开始的 $x_1, x_2, ..., x_{i-1}, i \leq n/2$ 的朝向都是朝右的，此时的 histgram 为 $v_{i-1}$，激活个数为 $\{k_1, k_2, ..., k_{n+1}\}$，因为 $x_1, x_2, ..., x_{i-1}$ 方向朝右，所以激活个数可以表示为 $\{k_i -i+1, k_i-i+2, ..., k_i-1,k_i, k_{i+1}, ..., k_{n+1}\}$. 如果 $x_i $ 方向朝右，则不做任何改变，令 $v_i = v_{i-1}$，如果 $x_i$ 方向朝左，那么改为朝右，此时激活个数变为 $\{k_i-i, k_i-i+1, ..., k_i-2, k_i-1, k_{i+1}+1, k_{i+2}+1, ..., k_{n+1}+1\}$. 因为 $|k_i - k_{i+1}| = 1$，所以 $k_{i+j} \geq k_i-j$，考虑配对 $(k_{i-j+1}, k_{i+j}) = (k_i - j + 1, k_i - j + t), j=1,2,..., i, t\geq 0$，这两个区域的激活个数载 $x_i$ 改变朝向后，变为 $(k_i-j, k_i - j+t+1)$，当 $t = 0$ 时，这些配对在计算 histgram 时是一样的，当 $t > 0$ 时，记 $V(s)$ 表示 $s$ 的 histgram，那么 $V(k_i -j, k_i - j+ t + 1)$

........ 发现证明错了。。。



**命题 2** 在递推的初值条件满足 $\gamma$ 的定义的情况下，任何满足下式的 $\gamma_{n,n'},n'>1$ 都符合其定义：
$$
\gamma_{n,n'} = \gamma_{n-1,n'-1} + \text{dm}(\gamma_{n,n'-1})
$$
证明：假设划分的超平面数量 $n'' < n'$ 时，$\gamma_{n,n''}$ 已知，且满足其定义的两个条件，我们证明上式计算出的 $\gamma_{n,n'}$ 满足定义中的两个条件。首先，第二个条件是显然成立的，因为 $\preceq$ 对于 $+$ 和 $\text{dm}$ 运算而言保持不变。下面主要证明第一个条件。

对于 $\gamma_{n,n'}$，即 $n$ 维空间中用 $n'$ 个超平面进行划分。对于任何一个划分结果 $S_h$，对应的 histgram 记为 $v_1$。$S_h$ 总可以看成其中的 $n'-1$ 个超平面划分之后，再用一个超平面划分的结果。假设其中的 $n'-1$ 个超平面划分之后的 histgram 是 $v_2$，则第 $n'$ 个超平面（记为 $l$）的划分将 $v_2$ 变成 $v_1$，我们具体分析这个变化过程。对于 $v_2$，设已经划分好的区域是 $\{R_1, R_2, ..., R_t\}$，设 $l$ 穿过其中的 $\{R_1, R_2, ..., R_p\}$，也就是 $l$ 将这 p 个区域分别一分为二。设 $l$ 的法向方向一侧的区域有 $\{R_{p+1}, R_{p+2}, ..., R_{p+q}\}$，另一侧的区域有 $\{R_{p+q+1}, ..., R_t\}$。由此我们将 $\{R_1, R_2, ..., R_t\}$ 分为了三个互不相交的子集，他们各自的激活数量的 histgram 为 $v_3,v_4, v_5$，那么 $v_2 = v_3 + v_4 + v_5$. 经过 $l$ 的划分，$\{R_1, R_2, ...,R_p\}$ 变成了 $\{R_1,R_1', ..., R_p, R_p'\}$ 2p 个区域（这里的 p 个区域沿用原来的记号，是为了简便），不妨设划分之后的 $\{R_1, R_2, ...,R_p\}$ 落在 $l$ 的不激活一侧，那么它们各自的激活数量不变，相对应的，$\{R_1', ..., R_p'\}$ 落在 $l$ 的激活一侧，所以激活数量相对于 $\{R_1,..., R_p\}$ 都加1. 而 $\{R_{p+1}, R_{p+2}, ..., R_{p+q}\}$ 的激活数量显然也加1，$\{R_{p+q+1}, ..., R_t\}$ 的激活数量不变。因此 $v_1 = v_3 + dm(v_3) + dm(v_4) + v_5$. 设增加 $l$ 前构成 $\{R_1, R_2, ...,R_p\}$ 的超平面为 $n'-1$ 个超平面中的 $m$ 个，记为 $L_m$，$m \leq n'-1$，这 m 个超平面和 $l$ 的交集 $L_m'$，在 $l$ 上构成了 $n-1$ 维空间（因为超平面 $l $ 是 $n-1$ 维空间）的 m 个超平面划分 $S_{h'}$，$L_m'$ 的法向是 $L_m$ 的法向在 $l$ 上投影。对任意 $1\leq i \leq p$，设 $R_i$ 的激活数量为 $k_i$，是 $L_m$ 的 $k_i$ 个超平面，这些超平面的集合记为 $L_{m,k_i}$。围成 $R_i$ 的超平面和 $l$ 的交所围成的区域 $r_i$ 是一一对应的，而且 $r_i$ 的激活超平面就是 $L_{m,k_i}$ 和 $l$ 的交，因此 $r_i$ 的激活数量和 $R_i$ 一样。所以 $v_3$ 就是 $S_{h'}$ 的激活数量的 histgram。因为任意 $1\leq n'' \leq n'$ 的 $\gamma_{n, n''}$ 满足定义的第一个条件和第二个条件，所以 $v_3 \preceq \gamma_{n-1,m} \preceq \gamma_{n-1, n'-1}$ **（这里的第二个不等号用的并不是第二个条件，而是新的一个条件，这个条件可以补充进来，因为显然应该满足）**。结合 $\text{dm}(v_3) + \text{dm}(v_4) + v_5 \preceq \text{dm}(v_3 + v_4 + v_5)$，得到：
$$
v_1 = v_3+ \text{dm}(v_3) + \text{dm}(v_4) + v_5 \\
\preceq \gamma_{n'-1,n'-1} + \text{dm}(v_3 + v_4 + v_5) \\
= \gamma_{n-1,n'-1} + \text{dm}(v_2) \\
\preceq \gamma_{n-1,n'-1} + \text{dm}(\gamma_{n,n'-1})
$$
证毕。



本来的想法是用命题 1 的初值条件和命题 2 的递推式推出所有的 $\gamma_{n,n'}$  的取值。但是现在命题 1 不成立了，需要找一个替代的初值条件。



## 和 Bounding and Counting Linear Regions of Deep Neural Networks, Thiago Serra, Christian Tjandraatmadja, Srikumar Ramalingam, 2018, ICML 的比较

事实上，可以证明 Bounding and Counting Linear Regions of Deep Neural Networks, Thiago Serra, Christian Tjandraatmadja, Srikumar Ramalingam, 2018, ICML 中的 $\gamma_{n,n'}$ 也满足命题 2，但是 $n=1$ 的取值很显然是一个 不好的上界。本来命题 1 的目的就是提出一个更紧的上界。如果满足条件的 $\gamma_{n,n'}$ 比其他人的更紧，或者说 $\preceq$ 其他人的 $\gamma_{n,n'}$，只要做到这一点，那么我们计算出来的上界一定比 Serra 2018 好。

下面的比较是原来的命题 1 下推导出来的结果。

![image-20200502153408951](/Users/xieyutong/Library/Application Support/typora-user-images/image-20200502153408951.png)

![image-20200502153449046](/Users/xieyutong/Library/Application Support/typora-user-images/image-20200502153449046.png)

同时也可以注意到，两者的差距并不时非常大（不知道当 $n'$ 很大的时候差别有多少）。

总结：我们给出的方法的核心是命题 2，这个命题在 Serra 2018 并没有出现，或者说他们证明上界的过程中，不是利用命题 2 来证明。而我们的上界的证明核心中，命题 2 是关键。如果 $n=1$ 的情形我们的取值和 Serra 2018 一样，那么最终的结果也是一样的。如果有更好的关于 $n$ 的结论，比如 $n = 2,n=3$ 这些低维情形的更紧的上界作为 $\gamma_{2,n'},\gamma_{3,n'}$，那么利用命题 2，就可以得到更紧的上界。



## 其他网络结构

### pooling

线性插值、average pooling、其他线性变换、strdie>0 的下采样，这四种等价于输入 $x$ 乘上矩阵 $A$，$A$ 一般都是满秩的，不妨设 rank(A) = k，则维度为 n 的 region，其 image 的维度为 $\min(k,n)$，所以当前划分区域的 image 的维度 histgram $v$ 的变化相当于 $\text{cl}_k(v)$，其矩阵形式和连接矩阵 $M$ 一样。

如果用的是 max pooling，这是一个非线性的结构，存在进一步的空间划分，根据 Serra 2018 的分析，一个 $k$-rank 的 $n_l$ 节点的 maxout 层（对于 stride=2 的 max pooling，假设输入是 $n$ 维，则 $n_l = n/4, k = 4$，记 $c = (k^2-k)n_l$，$v$ 的变化是：
$$
\text{cl}_{n_l}\left(diag\left\{\sum \gamma_{0,c},...,\sum\gamma_{n,c}\right\} v\right)
$$

证明：在 maxout 层的划分中，假设输入区域是 $n$ 维的，经过 maxout 层的运算，都可以看成是乘上了一个矩阵 $A\in \mathbb{R}^{n_{l-1}\times n_{l}}$，所以划分之后的子区域的 image 的维度小于等于 $\min\{n_{l-1}, n_l\}$，而原来的 $n$ 维区域，数量从 1 个被划分出了 $\sum\gamma_{n,c}$ 个，因此 histgram 的计算就变成上面的式子。证毕。



### unpooing

常见的线性插值、补0，这一类的运算仍等价于矩阵运算，且因为输出的维度大于输入的维度，所以 histgram $v$ 是不变的，只需要乘上相应的连接矩阵 $M$.

如果是 deconvolution，假设包含 ReLU 层，那么和一般的线性层 + ReLU 的变化是一样的。



### skip connection

这里考虑的 skip connection 是 concatenation 的形式。

有一个简单的引理，设 $x\in R$，$R$ 是一个 $k$ 维区域，则矩阵运算 $y = [I\text{ } A^T]^T x$，$R$ 映射之后 的区域的维度仍是 $k$.

假设 skip connection 定义在输入 $x$ 和输出 $y$ 之间，输入和输出之间的运算是某一网络结构，我们可以将这部分的 histgram 的变换记为：$v_y = A_t A_{t-1}\cdots A_1 v_x$，用矩阵计算得到一个综合矩阵，记为$B$，即 $v_y = B v_x$，因为 skip connection，实际的输出是 $(y\text{ } x)$，此时的 histgram 记为 $v_y'$。经过 $B$ 对应的网络计算，输入 $x$ 的每一个区域被进一步划分，假设某一个子区域，原来的空间维度是 $n_1$，因为 $y = Cx$，根据引理，有 skip connection 的情况下，$(y,x)$ 表示的 image 的维度仍然是 $n_1$，而区域的划分数量变多了。只考虑输入 $x$ 的一个区域，对应的 histgram 为 $e_{n_1}$，输出 $y$ 对应的划分结果是 $Be_{n_1}$，但是由于 skip connection，所以实际的 histgram 应该是 $|Be_{n_1}|_1e_{n_1}$，因为任何一个划分后的子区域的 image 维度不管在 $y$ 的这些分量是多少，都因为 $x$ 变成了 $n_1$。如果 $n_1$ 维的区域有 $k$ 个，那么划分后就是 $k|Be_{n_1}|_1e_{n_1}$，因为 $v_x = \sum v_{x,i}e_i$，所以有
$$
v_y' = \sum v_{x,i}|Be_i|_1e_i
$$
这个式子可以化简为：
$$
v_y = \sum v_{x,i}C_iBe_i
$$
$v_{x,i}$ 是 $v_x$ 的分量，$C_i$ 是一个第 $i$ 行全为 1，其余均为 0 的矩阵。上式进一步简化为 $v_y = B'E v_x$ 的矩阵形式。$B' = [C_0B \cdots C_n B]$，$E = [E_{0,0}\cdots E_{n,n}]^T$

如果有多个 skip connection 的嵌套，比如 U-net，可以先计算内层的 skip connection，然后再计算外层的 skip connection。

dense connection 和 residual connnection 是 skip connection 的特例和推广。



## 一般的随机连接的网络

定义网络结构：首先根据网络的前向最长路径，将该网络的形式改写。每一层的节点分为两个部分，一部分是参与下一层节点的计算，一个部分参与之后的某一层中的计算，对于后者，就是跳跃连接。

示例：

<img src="/Users/xieyutong/Library/Application Support/typora-user-images/image-20200502203027162.png" alt="image-20200502203027162" style="zoom:40%;" />

**命题 3** 设输入中参与运算的结点为 $x_1 \in \mathbb{R}^{n_{0,1}}$，不参与运算的结点为 $x_2 \in \mathbb{R}^{n_{0,2}}$，输出分为四个部分 $y_i \in \mathbb{R}^{n_{1,i}}$，分别表示 $x_1$ 运算后的输出中参与下一层运算的结点、$x_1$ 运算后的输出中会参与之后某一层的计算的结点、$x_2$ 中不参与下一层的计算而是之后某一层的计算结点、$x_2$ 中参与下一层的运算的结点（和上图的记号是一样的）。一般的随机连接的网络的单层形式可以表示为 $f(x_1, x_2) = (y_1, y_2, y_3, y_4)$，且 $(y_1, y_4)$ 相当于下一层的输入中的 $x_1$，$(y_2, y_3)$ 相当于下一层输入中的 $x_2$. 那么要计算的是划分区域的 image 的维度的分布 histgram 只要考虑 $x_1$ 部分的变化。即 $x_1$ 对应的 histgram 到 $(y_1, y_4)$ 的 histgram 的变化。不妨设 $x_1$ 对应的 region 的维度是 $n$，输入的 $v = e_{n}$，那么变换之后的 histgram 为：
$$
\text{dm}^{n_{1,4}}\left(\text{cl}_{\min\{n,n_{1,1}\}}\left(\gamma_{n,n_{1,1}} + \sum^{n_{1,2}-1}_{i=0}\text{cl}_{ n_{1,1}}\left(\gamma_{n-1,n_{1,1}+i}\right)\right)\right)
$$
上式构成了 histgram 变换的矩阵 $B$ 的第 $n+1$ 列。$B \in \mathbb{R^{n_{1,1}+n_{1,4}}}$，连接矩阵在这类网络的计算中也是需要的。

证明：

先给出一个引理：在 $n$ 维空间中，用 $k_1+k_2$ 个超平面进行划分，但是其中的 $k_2$ 个超平面不激活，此时的子区域的激活数量的 histgram 的上界是：
$$
\gamma_{n,k_1} + \sum^{k_2-1}_{i=0}\text{cl}_{ k_1}\left(\gamma_{n-1,k_1+i}\right)
$$
当 $k_2 = 1$ 时，类似于命题2 的证明，先用 $k_1$ 个超平面划分，histgram 是 $v_1$，第 $k_1+1$ 个超平面所分割的区域保持原来的维数（这部分的 histgram 记为 $v_2$），只增加数量，其他区域的维数也不变，，所以 histgram 的变化是：
$$
v' = v_1 + v_2 \preceq \gamma_{n,k_1} + \gamma_{n-1, k_1}
$$
当 $k_2 = t$ 时已成立，考虑 $k_2 = t+1$，设 $k_1 + t$ 个超平面划分后（ t 个超平面不激活）的激活数量 histgram 为 $v_1$，考虑第 $k_1 + t+1$ 个超平面划分的结果。不妨假设未激活的 t 个超平面激活，则新增的区域的激活数量的 histgram $v_2\preceq \gamma_{n-1,k_1+t}$，因为这 $t$ 个超平面实际上没有激活，所以实际的激活数量的 histgram $v_2'$ 满足 $v_2' \preceq \text{cl}_{k_1}(v_2)$，因此总的 histgram $v'$ 满足
$$
v‘ = v_1+ v_2' \preceq \gamma_{n,k_1} + \sum^{t-1}_{i=0}\text{cl}_{k_1}\left(\gamma_{n-1,k_1+i}\right) + \text{cl}_{k_1}(\gamma_{n-1, k_1+t}) = \gamma_{n,k_1} + \sum^{t}_{i=0}\text{cl}_{ k_1}\left(\gamma_{n-1,k_1+i}\right)
$$
引理证毕。

回到随机连接的网络的变换证明中。我们可以把 region 维度的 histgram 的变化按如下的分析进行：首先是 n 维空间被 $n_{1,1} + n_{1,2}$ 个超平面划分，因为其中 $n_{1,2}$ 个神经元的激活结果不参与下一层运算，所以 image 的维度不应该考虑这些神经元，只能考虑 $n_{1,1}$ 个神经元的激活情况。根据引理，此时的激活数量的 histgram 是
$$
\gamma_{n,n_{1,1}} + \sum^{n_{1,2}-1}_{i=0}\text{cl}_{ n_{1,1}}\left(\gamma_{n-1,n_{1,1}+i}\right)
$$
考虑到 image 的维度限制，所以增加了一个 $\text{cl}_{\min\{n,n_{1,1}\}}$ 运算。在下一层计算时，输入还包含 $y_4$，所以每个 image 的维度增加了 $n_{1,4}$ 维，所以增加一个 $\text{dm}^{n_{1,4}}$ 的运算。

上述的计算针对的是输入的一个 $n$ 维区域，所以构成了变换的矩阵 $B$ 的第 $n+1$ 列。证毕。



## 卷积线性层实现的区域划分

卷积层和全连接层的差别在于前者对应的线性矩阵中有很多0，具有一定的结构，而后者则是一般化情形的线性矩阵。卷积层的一个神经元，其实是卷积核在输入上进行窗口滑动时，局部的线性求和，所以参与计算的只是输入中的部分维度，因此空间划分并不能最大化。

一个简单的例子，考虑一个 2 维空间，划分该空间的超平面（也就是直线），其法向量总有一个分量为0（类似于卷积层中的局部线性求和，对应的超平面的法向量只有少数分量不为0，其余为0），那么相当于下图的划分：

<img src="/Users/xieyutong/Library/Application Support/typora-user-images/image-20200507144839694.png" alt="image-20200507144839694" style="zoom:50%;" />

很显然这样划分出来的空间数量比相同数量下随意的直线划分的空间数量少。因此卷积层实现的空间划分数量应该有更紧的上界。

假设有一层卷积层（只考虑2维多通道情形），输入的维度是 $n_w\times n_h\times c_0$，分别对应宽、高和通道数，输出的维度是 $m_w \times m_h \times c_1$，卷积核的 size 为 $k_w \times k_h$，stride 为 $s_w\times s_h$.

卷积层的线性运算对应的超平面和卷积核的滑动窗口、输出通道数是一一对应的，为了便于分析卷积层（+ReLU）实现的空间划分的数量，可以将这些滑动窗口分为两类。一类是滑动窗口互不相交，比如下图中的实线所指的窗口，剩下的所有滑动窗口归为一类，它们与第一类的滑动窗口是相交的。

<img src="/Users/xieyutong/Library/Application Support/typora-user-images/image-20200507144910985.png" alt="image-20200507144910985" style="zoom:50%;" />

下面给出一个引理：设输入向量的维度是 $n'$，输入区域 $R$ 的空间维度是 $n$，被 $k_1 + k_2$ 个超平面划分，设有两个下标集 $M_1, M_2$，$|M_1|=m_1, |M_2|=m_2$，且 $M_1$ 和 $M_2$ 的交集是空集。下标集中的下标都属于超平面法向量的下标集 $[n']$，其中 $k_1$ 个超平面（它们的集合设为 $K_1$）的法向量在 $M_2$ 的分量中为 0，但在 $M_1$ 的分量中不全为0，剩下的 $k_2$ 个超平面（它们的集合设为 $K_2$）相反，其法向量在 $M_1$ 的分量中为0，在 $M_2$ 的分量中不全为0。也就是说 $K_1$ 中的任何一个超平面的法向量和 $K_2$ 中的超平面的法向量是相互垂直的。定义 histgram 的运算 $\star$
$$
v^{(1)}\star v^{(2)} = \sum_{i,j\geq 0} v_{i}^{(1)}v_{j}^{(2)}e_{i+j} = \sum_{i\geq 0} \text{dm}^{v_i^{(1)}}(v^{(1)}_iv^{(2)}) =  \sum_{j\geq 0} \text{dm}^{v_j^{(2)}}(v^{(2)}_j v^{(1)}) 
$$
运算 $\star$ 有性质 $|v^{(1)}\star v^{(2)}|_1 = |v^{(1)}|_1\cdot |v^{(2)}|_1$

那么输入区域 $R$ 被这 $k_1+k_2$ 个超平面划分后的子区域的激活数量的 histgram 满足：
$$
v \preceq \gamma_{m_1,k_1}\star\gamma_{m_2,k_2} \\\text{or } \sum_{j=1}^{k_2-i-1} \text{dm}^{i-1}(\gamma_{n-1, k_2-i}) + \text{dm}^{k_2-i-1}(\gamma_{m_1, k_1}) \\\text{or } \gamma_{n, k_1+k_2}
$$
证明：因为 $K_i, i= 1,2$ 的法向量下标中非0的数量有限，$K_i $ 的划分效果相当于 $R$ 投影到 $\mathbb{R}^{n'}$ 的 $m_i$ 维子空间后，被 $k_i$ 个超平面划分。考虑三种情况，$n \geq m_1 + m_2$，$\min\{m_1, m_2\} \leq n < m_1 + m_2$，$n< \min\{m_1, m_2\}$，不妨设 $m_1 \leq m_2$。

$n \geq m_1 + m_2$ 时，因为 $M_1$ 和 $M_2$ 不相交，所以 $K_1$ 对 $R$ 划分的子区域，任何一个都可以被 $K_2$中的超平面继续划分，且划分结果的最大可能等价于 $R$ 本身被 $K_2$ 划分的效果（很容易可以举出例子）。虽然 $R$ 的空间维度是 $n > m_1$，但 $K_1$ 对 $R$ 的划分因为 $K_1$ 的法向量的下标集是 $M_1$，所以划分数量和激活数量等价于 $R$ 投影到 $\mathbb{R}^{n'}$ 的 $m_1$ 维子空间（这个子空间由 $M_1$ 的下标决定）后被 $k_1$ 个超平面划分的结果。设 $R$ 投影后的空间维度是 $p_1$，则 $p_1 \leq m_1$，划分后的子区域的激活数量的 histgram 是 $v_1$，上界是 $\gamma_{p_1, k_1} \preceq \gamma_{m_1, k_1}$。每一个子区域被 $K_2$ 继续划分，划分结果的 histgram 是 $v_2$，上界类似可以得出是 $\gamma_{m_2, k_2}$。最终的每个子区域的激活数量应该是 $K_1$ 划分时的激活数量和 $K_2$ 划分时的激活数量之和，因此最终的 histgram 的计算是 $v_1\star v_2$，上界应该是 $\gamma_{m_1,k_1}\star\gamma_{m_2,k_2}$。

$\min\{m_1, m_2\} \leq n < m_1 + m_2$ 时，$K_1$ 的划分结果的激活数量的 histgram 的上界依照刚才的分析可知是 $\gamma_{m_1, k_1}$，对于剩下的 $K_2$ 的划分，因为 $n < m_1 + m_2$，如果按照 $n\geq m_1 + m_2$ 的方法分析，虽然同样可以证明是上界，但是显然该上界取到的条件是 $n \geq m_1 + m_2$，当这一条件不满足时，应该有更紧的上界。我们可以把 $K_1, K_2$ 的划分看成先用 $K_1$ 对 $R$ 划分，然后再依次用 $K_2$ 的超平面进一步划分。根据命题 2 的证明及结论，设划分对象是 $n$ 维区域 $R$，$v_k$ 表示用 $k$ 个超平面（构成集合 $P_k$）划分后的激活数量的 histgram，$v_i, i< k$ 表示用 $i$ 个超平面（构成集合 $P_i, P_i \subseteq P_{i+1} \subseteq \cdots \subseteq P_k$ ）划分的 histgram，则有下面的式子（*式）：
$$
\begin{aligned}
v_k &\preceq \gamma_{n-1, k-1} + \text{dm}(v_{k-1})\\
& \preceq \gamma_{n-1, k-1} + \text{dm}(\gamma_{n-1,k-2} + \text{dm}({v_{k-2}}))\\
&\cdots \\
& \preceq \sum_{j=1}^{k-i-1} \text{dm}^{i-1}(\gamma_{n-1, k-i}) + \text{dm}^{k-i-1}(v_i)

\end{aligned}
$$
令 $v_i = v_{k_1} \preceq \gamma_{m_1, k_1}$，在考虑 $K_2$ 的超平面划分时，均在 $n$ 维区域中考虑。（这部分也可以写成一个引理）

当 $n < \min\{m_1, m_2\} $ 时，则直接用 $\gamma_{n, k_1+k_2}$ 作为上界。

证毕。



回到卷积层的划分数量的上界的计算。类似于引理的分析，我们可以先把所有的滑动窗口分成前述的两类，先计算第一类窗口中位于左上角第一个窗口 $w_1$ 的超平面的划分效果（$c_1$ 个超平面），然后计算向右滑动的第一个和 $w_1$ 不相交的窗口 $w_2$ 的划分效果，计算方式则和引理一样。因为窗口大小和输入的通道数已知，所以 $m_1 = m_2 = c_0k_wk_h $，根据 $n$ 和 $m_1, m_2$ 的大小关系决定计算方式。考虑包含 $w_1, w_2$ 的最小区域（设一共涉及到 $p$ 个位置，$p$ 的计算取决于具体参数）中的其他窗口，这些窗口属于第二类窗口，因为它们和 $w_1, w_2$ 都相交，此时参照引理中的 $\min\{m_1, m_2\} \leq n < m_1 + m_2$ 的计算方式，将新增加超平面的划分效果用 * 式的计算方法计算。不过此时 $\gamma$ 下标中的 $n$ 应该是 $\min\{pc_0, n\}$。类似地，继续计算下一个第一类窗口 $w_3$，包含 $w_1, w_2, w_3$ 的最小区域中的其他第二类窗口......值的注意的是，一旦考虑到的 $pc_0 > n$，可以直接用引理中的 *式计算剩下所有的超平面。如果还有剩余的第二类窗口（比如最右侧和最下方），那么计算时根据增加的维度修改 $n$ 值。

用上述方法计算出的 histgram 的上界记为 $\delta_{n,h}$， $h$ 表示卷积层的所有参数，类似 $\gamma_{n,n'}$ 和 $B_{n'}$ 的关系， $\text{cl}_{n}(\delta_{n,h})$ 是该卷积层对应 histgram 矩阵变换的第 $n+1$ 列。