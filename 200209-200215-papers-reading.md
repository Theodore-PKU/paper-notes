# 200209-200215 论文阅读总结

[TOC]

本周一共读了 47 篇文章。

## 论文列表

1. [Solving ill-posed inverse problems using iterative deep neural networks](https://github.com/Theodore-PKU/paper-notes/blob/master/solving-ill-posed-inverse-problems-using-iterative-deep-neural-networks-2017-200209.md): Inverse Problems
2. Deep Component Analysis via Alternating Direction Neural Networks: Component Analysis
3. [Intelligent Parameter Tuning in Optimization-Based Iterative CT Reconstruction via Deep Reinforcement Learning](https://github.com/Theodore-PKU/paper-notes/blob/master/Intelligent-parameter-tuning-in-optimization-based-iterative-ct-reconstruction-via-deep-reinforcement-learning-2018-200209.md): RL for parameter tuning 
4. [KIKI-net: cross-domain convolutional neural networks for reconstructing undersampled magnetic resonance images](https://github.com/Theodore-PKU/paper-notes/blob/master/kiki-net-cross-domain-convolutional-neural-networks-for-reconstructing-undersampled-magnetic-resonance-images-2018-200209.md): MRI
5. A Region of Interest Prediction Method for RealTime Online Dynamic Magnetic Resonance Imaging: MRI
6. [Learning Personalized Representation for Inverse Problems in Medical Imaging Using Deep Neural Network](https://github.com/Theodore-PKU/paper-notes/blob/master/Learning-personalized-representation-for-inverse-problems-in-medical-imaging-using-deep-neural-network-2018-200209.md): PET
7. Multi-bin Trainable Linear Unit for Fast Image Restoration Networks: activation function
8. Coupled Dictionary Learning for Multi-Contrast MRI Reconstruction: dictionary learning
9. [Image Reconstruction by Splitting Deep Learning Regularization from Iterative Inversion](https://github.com/Theodore-PKU/paper-notes/blob/master/image-reconstruction-by-splitting-deep-learning-regularization-from-iterative-inversion-2018-200210.md): inverse problem
10. When Smart Signal Processing Meets Smart Imaging: Review 
11. [The Power of Complementary Regularizers: Image Recovery via Transform Learning and Low-Rank Modeling](https://github.com/Theodore-PKU/paper-notes/blob/master/The-power-of-complementary-regularizers-image-recovery-via-transform-learning-and-low-rank-modeling-2018-200210): inverse problem
12. [Subject-Speciﬁc Convolutional Neural Networks for Accelerated Magnetic Resonance Imaging](https://github.com/Theodore-PKU/paper-notes/blob/master/subject-specific-convolutional-neural-networks-for-accelerated-magnetic-resonance-imaging-2018-200210.md): parallel imaging
13. [SC2Net: Sparse LSTMs for Sparse Coding](https://github.com/Theodore-PKU/paper-notes/blob/master/sc2net-sparse-lstms-for-sparse-coding-sparse-coding-2018-200210.md): sparse coding
14. [Learned Primal-dual Reconstruction](https://github.com/Theodore-PKU/paper-notes/blob/master/learned-primal-dual-reconstruction-2018-200210.md): inverse problem
15. [Deep Bayesian Inversion](https://github.com/Theodore-PKU/paper-notes/blob/master/deep-bayesian-inversion-2018-200211): inverse problem
16. [Learning-based Image Reconstruction via Parallel Proximal Algorithm](https://github.com/Theodore-PKU/paper-notes/blob/master/learning-based-image-reconstruction-via-parallel-proximal-algorithm-2018-200211.md): inverse problem
17. Rapid Compositional Mapping of Knee Cartilage With Compressed Sensing MRI
18. [Deep BCD-Net Using Identical Encoding-Decoding CNN Structures for Iterative Image Recovery](https://github.com/Theodore-PKU/paper-notes/blob/master/deep-bcd-net-using-identical-encoding-decoding-cnn-structures-for-iterative-image-recovery-2018-200211.md): inverse problem
19. Content-aware compressive magnetic resonance image reconstruction: MRI
20. [k-space Aware Convolutional Sparse Coding: Learning from Undersampled k-space Datasets for Reconstruction](https://github.com/Theodore-PKU/paper-notes/blob/master/k-space-aware-convolutional-sparse-coding-learning-from-undersampled-kspace-datasets-for-reconstruction=2018-200211.md): MRI 
21. [3D BPConvNet to reconstruct parallel MRI](https://github.com/Theodore-PKU/paper-notes/blob/master/3d-bpconvnet-to-reconstruct-parallel-mri-2018-200211.md): MRI
22. Single-shot T 2 mapping using overlapping-echo detachment planar imaging and a deep convolutional neural network
23. Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations: network and differential equations
24. [CREAM: CNN-REgularized ADMM Framework for Compressive-Sensed Image Reconstruction](https://github.com/Theodore-PKU/paper-notes/blob/master/cream-cnn-regularized-admm-framework-for-compressive-sensed-image-reconstruction-2018-200212.md): CS
25. Neural Network-based Microscope Defocus Correction With Point Spread Function Recovery: deblur
26. Rank Minimization for Snapshot Compressive Imaging: SCI
27. Recurrent Generative Adversarial Neural Networks for Compressive Imaging: MRI
28. A deep network for tissue microstructure estimation using modiﬁed LSTM units: others
29. A Model-Driven Deep Learning Network for MIMO Detection: MIMO
30. [A Divide-and-Conquer Approach to Compressed Sensing MRI](https://github.com/Theodore-PKU/paper-notes/blob/master/a-divide-and-conque-approach-to-compressed-sensing-mri-2019-200213.md): MRI
31. [Accelerating CS-MRI Reconstruction With Fine-Tuning Wasserstein Generative Adversarial Network](https://github.com/Theodore-PKU/paper-notes/blob/master/accelerating-cs-mri-reconstruction-with-fine-tuning-wasserstein-generative-adversarial-network-2019-200213.md): MRI
32. [Accelerating Optimization Algorithms With Dynamic Parameter Selections Using Convolutional Neural Networks For Inverse Problems In Image Processing](https://github.com/Theodore-PKU/paper-notes/blob/master/): inverse problem
33. Spectral data completion for dual-source x-ray CT: CT
34. Pan-sharpening via a gradient-based deep network prior: Pan-sharpening
35. A comparative study of CNN-based super-resolution methods in MRI reconstruction and its beyond: MRI
36. [Learning Cluster Structured Sparsity By Reweighting](https://github.com/Theodore-PKU/paper-notes/blob/master/learning-cluster-structured-sparsity-by-reweighting-2019-200214.md): sparsity recovery
37. [MRI Reconstruction with Interpretable Pixel-Wise Operations Using Reinforcement Learning](https://github.com/Theodore-PKU/paper-notes/blob/master/mri-reconstruction-with-interpretable-pixel-wise-operations-using-reinforcement-learning-2019-200214.md): RL
38. [Highly undersampled magnetic resonance imaging reconstruction using autoencoding priors](https://github.com/Theodore-PKU/paper-notes/blob/master/highly-undersampled-magnetic-resonance-imaging-reconstruction-using-autoencoding-priors-2020-200214.md): MRI
39. Learning step sizes for unfolded sparse coding: optimization
40. Image Reconstruction: From Sparsity to Data-adaptive Methods and Machine Learning: Review

41. [ADMM-based deep reconstruction for limited-angle CT](https://github.com/Theodore-PKU/paper-notes/blob/master/admm-based-deep-reconstruction-for-limited-angle-ct-2019-200215.md): CT
42. [On the Convergence of ADMM with Task Adaption and Beyond](https://github.com/Theodore-PKU/paper-notes/blob/master/on-the-convergence-of-admm-with-task-adaption-and-beyong-2019-200215.md): admm
43. [On the Convergence of Learning-based Iterative Methods for Nonconvex Inverse Problems](https://github.com/Theodore-PKU/paper-notes/blob/master/on-the-convergence-of-learning-based-iterative-methods-for-nonconvex-inverse-problems-2019-200215.md): optimization
44. Reconstruction techniques for cardiac cine MRI: review
45. [Plug-and-Play Methods Provably Converge with Properly Trained Denoisers](https://github.com/Theodore-PKU/paper-notes/blob/master/plug-and-play-methods-provably-converge-with-properly-trained-denoisers-2019-200215.md): optimization
46. [JSR-Net: A Deep Network for Joint Spatial-radon Domain CT Reconstruction from Incomplete Data](https://github.com/Theodore-PKU/paper-notes/blob/master/jsr-net-a-deep-network-for-joint-spatial-radon-domain-ct-reconstruction-from-incomplete-data-2019-200215.md): CT
47. Learning to Regularize Using Neumann Networks: inverse problem

## Ideas from papers

- 把重建的图像划分成几个不同的部分（高频和低频）进行重建，然后再合并（A Divide-and-Conquer Approach to Compressed Sensing MRI）



## 个人思考

- 假设神经网络对图像空间进行了划分，这种划分有什么性质？是否存在很多划分的子空间是无效的？处于相同子空间的图像是什么样的？这是否可以说明为什么神经网络需要很多的参数？冗余的参数其实是为了保证有效的图像只处于其中的少数子空间？如果划分的子空间太少，比如过多的下采样，是否意味着就很难精细地刻画出这个图像，控制划分的数量对于模型表现的影响可能是非常关键的。既然图像处于低维流形，那么有什么办法可以消除冗余的子空间吗，这样网络就可以直接成为一种稀疏性的度量？或者说能不能建立子空间划分和稀疏性的某种关系？

